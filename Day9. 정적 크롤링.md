# Day9. ì •ì  í¬ë¡¤ë§

## íŒŒì´ì¬ ì½”ë“œ

ì½”ë“œì˜ ê¸°ëŠ¥

1)ì—¬ëŸ¬ í˜ì´ì§€ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ìˆ˜ì§‘

2)ì›í•˜ëŠ” ì½˜í…ì¸ (í‚¤ì›Œë“œ)ì…ë ¥ë°›ê¸°

```python
#ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import requests
from bs4 import BeautifulSoup

#ì›í•˜ëŠ” ì½˜í…ì¸ (í‚¤ì›Œë“œ)ì…ë ¥ë°›ê¸°
keyword = input("ë‰´ìŠ¤ ê²€ìƒ‰ í‚¤ì›Œë“œ: ")
#ë‰´ìŠ¤ ê¸°ì‚¬ë§ˆë‹¤ ë²ˆí˜¸ ë¶™ì´ê¸°
count = 0

#1~10í˜ì´ì§€ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ìˆ˜ì§‘
for page in range(1, 3):
    #í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ në²ˆì§¸ í˜ì´ì§€
    news_url = 'https://search.hankyung.com/apps.frm/search.news?query=' + keyword + '&page=' + str(page)
    #í˜ì´ì§€ë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ ë°›ì•„ì˜¤ê¸°
    raw = requests.get(news_url)
    
    #htmlì½”ë“œë¡œ ë³€í™˜
    soup = BeautifulSoup(raw.text, 'html.parser')
    
    #ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ìˆ˜ì§‘
    box = soup.find('ul', {'class' : 'article'})
    all_title = box.find_all('em', {'class': 'tit'})

    #ì¶œë ¥
    for title in all_title:
        count += 1
        t = title.text
        print(count, '-', t.strip())
```

**âœ… ì˜¤ëŠ˜ì˜ ë¬¸ì œ: í•œêµ­ê²½ì œë‰´ìŠ¤ í¬ë¡¤ë§**

ì˜¤ëŠ˜ ì‹¤ìŠµì„ í†µí•´ 'ì „ì²´ë‰´ìŠ¤'ë¥¼ í¬ë¡¤ë§í•´ë³´ì•˜ì£ !

ì´ë²ˆ ê³¼ì œëŠ” 'í•œêµ­ê²½ì œë‰´ìŠ¤'ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤ğŸ˜

'í•œêµ­ê²½ì œë‰´ìŠ¤'ì˜ url ì£¼ì†Œ íŒ¨í„´ì€ ì €ë²ˆ ì‹œê°„ì˜ ë¬¸ì œë¥¼ í’€ë©° í™•ì¸í•˜ì…¨ì„ê±°ì—ìš”!

ì˜¤ëŠ˜ì˜ ë¬¸ì œëŠ” **ì•„ë˜ì˜ ìš”êµ¬ ì‚¬í•­**ì„ ì˜ ë”°ë¼ì„œ ì§„í–‰í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤!

**â­ ì¡°ê±´ â­**

- 'ì „ì²´ë‰´ìŠ¤'ê°€ ì•„ë‹Œ 'í•œêµ­ê²½ì œ ë‰´ìŠ¤' í¬ë¡¤ë§
- ë³¸ì¸ì´ ê´€ì‹¬ ìˆëŠ” í‚¤ì›Œë“œë¥¼ input()ìœ¼ë¡œ ì…ë ¥ë°›ê¸°
- ì¶œë ¥ ìš”ì†ŒëŠ” 2ê°œ: ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª©, ê¸°ì‚¬ ì‘ì„± ë‚ ì§œ ë° ì‹œê°„
- 1, 2í˜ì´ì§€ì˜ ë‰´ìŠ¤ 20ê°œë§Œ ì¶œë ¥
- ì†ŒìŠ¤ì½”ë“œ ë° ì¶œë ¥ ê²°ê³¼ ì¸ì¦

**ğŸ‘‰ ê²°ê³¼ ì˜ˆì‹œ â­**

![img](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2c34c03e-bcd8-4fda-ac50-2299da98250f%2FUntitled.png?table=block&id=c3bf1182-3457-4009-96b8-512a1bea6d5c&width=1150&userId=0bf67c59-da73-4d74-b499-88019e309008&cache=v2)

![img](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53d5d8b6-c15e-4a60-8de1-6c2ab68a423e%2FUntitled.png?table=block&id=c95c8027-a968-49e1-b015-6d48b693fa58&width=2730&userId=0bf67c59-da73-4d74-b499-88019e309008&cache=v2)

**â­ íŒíŠ¸ â­**

- 'ì „ì²´ë‰´ìŠ¤'ì™€ 'í•œêµ­ê²½ì œë‰´ìŠ¤'í˜ì´ì§€ì˜ ë™ì¼í•œ ìš”ì†Œ (ê¸°ì‚¬ 10ê°œë¥¼ í¬í•¨í•œ í° í‹€, ê¸°ì‚¬ ì œëª© ë“±)ë“¤ì€ íƒœê·¸ ë° ì„ íƒìê°€ ëª¨ë‘ ë™ì¼í•©ë‹ˆë‹¤.
- ê·¸ë ‡ë‹¤ë©´ ì˜¤ëŠ˜ì˜ ì½”ë“œì—ì„œ url ì£¼ì†Œë¥¼ ìˆ˜ì •í•˜ê³ , 'ë‚ ì§œ ë° ì‹œê°„'ì„ ì¶œë ¥í•˜ë„ë¡ ìˆ˜ì •í•˜ë©´ ë˜ê² ì£ ?

```python
# ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import requests
from bs4 import BeautifulSoup

# ì›í•˜ëŠ” ì½˜í…ì¸ (í‚¤ì›Œë“œ)ì…ë ¥ë°›ê¸°
keyword = input("ë‰´ìŠ¤ ê²€ìƒ‰ í‚¤ì›Œë“œ: ")
# ë‰´ìŠ¤ ê¸°ì‚¬ë§ˆë‹¤ ë²ˆí˜¸ ë¶™ì´ê¸°
count = 0

# 1~10í˜ì´ì§€ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ìˆ˜ì§‘
for page in range(1, 3):
    # í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ në²ˆì§¸ í˜ì´ì§€
    news_url = 'https://search.hankyung.com/apps.frm/search.news?query=' + keyword + '&mediaid_clust=HKPAPER,HKCOM&page=' + str(page)
    # í˜ì´ì§€ë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ ë°›ì•„ì˜¤ê¸°
    raw = requests.get(news_url)

    # htmlì½”ë“œë¡œ ë³€í™˜
    soup = BeautifulSoup(raw.text, 'html.parser')

    # ë‰´ìŠ¤ ê¸°ì‚¬ ì œëª© ìˆ˜ì§‘
    box = soup.find('ul', {'class': 'article'})
    all_title = box.find_all('em', {'class': 'tit'})
    all_datetime=box.find_all('span', {'class':'date_time'})

    for i in range(10):
        count+=1
        t=all_title[i].text.strip()+' '+all_datetime[i].text.strip()
        print(count, '-', t)
```

